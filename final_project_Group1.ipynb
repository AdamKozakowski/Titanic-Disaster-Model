{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S8EghnyjxYg"
   },
   "source": [
    "# Titanic disaster model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inrotuction\n",
    "#### to do:\n",
    "- briefly describe model\n",
    "- talk about recent methods used for problems like this\\\n",
    "- talk about methods we want to use\n",
    "- what do we expect\n",
    "\n",
    "https://www.kaggle.com/competitions/titanic\n",
    "\n",
    "https://www.kaggle.com/code/alexisbcook/titanic-tutorial/notebook\n",
    "\n",
    "https://www.overleaf.com/read/fqxnygwqtnjs#fbe3c8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxNBdgCNCZSn"
   },
   "source": [
    "### Seting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from scipy import optimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize, LinearConstraint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "The dataset used in the project was downloaded from github repository provided by Kaggle: https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/. \n",
    "\n",
    "It came with data dictionary with definitions of values and keys of the dataset. From left variables were as fallows: survival - Survival result (0 = No, 1 = Yes), Pclass\t- ticket class\t(1 = 1st, 2 = 2nd, 3 = 3rd), Sex - sex,\n",
    "Age\t   -     age in years, \n",
    "Sibsp\t-    number of siblings / spouses aboard the Titanic, \t\n",
    "Parch\t-     number of parents / children aboard the Titanic\t\n",
    "Ticket\t-    ticket number, \n",
    "Fare\t-    passenger fare\t\n",
    "Cabin\t-    cabin number\t\n",
    "Embarked -\tport of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1700692440573,
     "user": {
      "displayName": "Kirill Korzuk",
      "userId": "04732590717018364342"
     },
     "user_tz": -180
    },
    "id": "C0ZWTfkFj8XM",
    "outputId": "5c778832-e116-4fb5-96f0-eef0058f510c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_path = 'https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/'\n",
    "df_train = pd.read_csv(gh_path + 'train.csv')\n",
    "df_test = pd.read_csv(gh_path + 'test.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59rMrjvLCnLY"
   },
   "source": [
    "### Feature engineering\n",
    "Main task in this section was to prepare dataset for modeling. It was necessary to remove certain features that were redundant, that is \"Name\", \"Ticket\", \"Cabin\" and \"Embarked\". It was concluded, that name of the passenger, port of embarkation, ticket and cabin number were meaningless for analysis. Nevertheless, we concluded, that cabin placement on ship might have had influence on priority over reaching the lifeboats. Information about cabin placement could be hidden in ticket's fare,. This feature was left in dataset to include passenger placement in model.\n",
    "\n",
    "Another change that had to be made was the change of sex's values from string to binary. In the project attributes for male and female were assigned to 0 and 1 respectively.\n",
    "\n",
    "Last thing that was done, was the drop of keys with missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "XvEKGNJ6Crfu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
      "0              1         0       3    0  22.0      1      0   7.2500\n",
      "1              2         1       1    1  38.0      1      0  71.2833\n",
      "2              3         1       3    1  26.0      0      0   7.9250\n",
      "3              4         1       1    1  35.0      1      0  53.1000\n",
      "4              5         0       3    0  35.0      0      0   8.0500\n",
      "..           ...       ...     ...  ...   ...    ...    ...      ...\n",
      "885          886         0       3    1  39.0      0      5  29.1250\n",
      "886          887         0       2    0  27.0      0      0  13.0000\n",
      "887          888         1       1    1  19.0      0      0  30.0000\n",
      "889          890         1       1    0  26.0      0      0  30.0000\n",
      "890          891         0       3    0  32.0      0      0   7.7500\n",
      "\n",
      "[714 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Name','Ticket', 'Cabin', 'Embarked']\n",
    "df_train_processed = df_train.drop(columns=columns_to_drop)\n",
    "df_test_processed = df_test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop keys with any NaN values\n",
    "df_train_processed = df_train_processed.dropna()\n",
    "\n",
    "# Change nan values for statisticaly correct values\n",
    "average_age = df_test_processed['Age'].mean()\n",
    "df_test_processed['Age'].fillna(average_age, inplace=True)\n",
    "\n",
    "average_fare_train = df_test_processed['Fare'].mean()\n",
    "df_test_processed['Fare'].fillna(average_fare_train, inplace=True)\n",
    "\n",
    "# Sex changed to binary\n",
    "df_train_processed['Sex'] = df_train_processed['Sex'].replace({'male': 0, 'female': 1})\n",
    "df_test_processed['Sex'] = df_test_processed['Sex'].replace({'male': 0, 'female': 1})\n",
    "\n",
    "print(df_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processed train dataset was next splited into training and testing sets using train_test_split functntion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_train_processed['Survived'].values\n",
    "X = df_train_processed[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMJqmV_FCw36"
   },
   "source": [
    "### Perceptron\n",
    "\n",
    "#### To do:\n",
    "- define weight vector W (imo randomly) and training set X\n",
    "- DONE definition of perceptron class (linear, binary[if survived would be changed to -1 and 1] or/and LOGISTIC). That would include: activation function, loss function, fiting (gradient descent/newton-rap), all can be copied and slightly modified form collab \"logistic_regression_and_svm\",\n",
    "- spliting training dataset and look for bad predictions,\n",
    "- comparason with scikit-learn method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1700566854641,
     "user": {
      "displayName": "Adam Kozakowski",
      "userId": "03759211285170292721"
     },
     "user_tz": -60
    },
    "id": "ND2iJXTwCwnD",
    "outputId": "4b465522-e449-4195-effd-2eb87646d420"
   },
   "outputs": [],
   "source": [
    "class PerceptronLogistic:\n",
    "    def __init__(self, W : np.array,  b = 0, epo = 100, lr = 0.01):\n",
    "        self.W = W\n",
    "        self.N = len(W)\n",
    "        self.b = b\n",
    "        # how many learning iterations we give\n",
    "        self.epo = epo\n",
    "        # what is our step in the gradient\n",
    "        self.lr = lr\n",
    "    def get_N(self):\n",
    "        return self.N\n",
    "    \n",
    "    def get_b(self):\n",
    "        return self.b\n",
    "    \n",
    "    def get_W(self):\n",
    "        return self.W\n",
    "    \n",
    "    ############################## SETTERS ##############################\n",
    "    \n",
    "    # Create setters for the perceptron\n",
    "    def set_N(self, N):\n",
    "        self.N = N\n",
    "        self.W = np.zeros(N)\n",
    "        \n",
    "    def set_b(self, b):\n",
    "        self.b = b\n",
    "        \n",
    "    def set_W(self, W : np.array):\n",
    "        if W.ndim != 1:\n",
    "            print(\"Cannot set such weights -> dimension wrong\")\n",
    "            return\n",
    "        self.N = W.shape[0]\n",
    "        self.W = W\n",
    "    \n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def set_epo(self, epo):\n",
    "        self.epo = epo\n",
    "    ############################## GETTERS OVERRIDE ##############################\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.W[key]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.W[key] = value\n",
    "        \n",
    "    def __getslice(self, i, j):\n",
    "        return self.W[i:j]\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.lr\n",
    "\n",
    "    def get_epo(self):\n",
    "        return self.epo\n",
    "    \n",
    "    # set the string output of the perceptron \n",
    "    def __str__(self):\n",
    "        return f\"Am a perceptron of N={self.N} dimension{'s' if self.N > 1 else ''} biased with b={self.b}\"    \n",
    "\n",
    "    ############################## OPERATORS OVERRIDE ##############################\n",
    "     \n",
    "    def __mul__(self, other):\n",
    "        return self.activation_function(other)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self.__mul__(other)\n",
    "\n",
    "    ############################## PERCEPTRON METHODS ##############################\n",
    "    \n",
    "    '''\n",
    "    Net output is the basic body action of the perceptron. On top of it, the activation function is used.\n",
    "    '''\n",
    "    def net_output(self, X):\n",
    "        return np.dot(X, self.W) + self.b\n",
    "\n",
    "    def activation_function(self, X):\n",
    "        net_output = self.net_output(X)\n",
    "        return (1.0 / (1.0 + np.exp(-np.clip(net_output, -500, 500)))).reshape(-1, 1)\n",
    "\n",
    "    def loss(self, y_true: np.array, y_pred: np.array):\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return -np.sum(np.multiply(y_true, np.log(y_pred)) + np.multiply((1.0 - y_true), np.log(1.0 - y_pred)))\n",
    "\n",
    "    def gradient(self, x_true, y_true, prediction):\n",
    "        val = y_true - prediction\n",
    "        suma_w = np.dot(val, x_true)\n",
    "        suma_b = np.sum(val)\n",
    "        return suma_b, suma_w\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.activation_function(X)    \n",
    "\n",
    "    def fit(self, X, y, randomstate = None, batch = 1, verbose = False):\n",
    "        '''\n",
    "        Fit function allows to obtain the (probably most?) correct weights for the perceptron via the gradient descent algorithm.\n",
    "        '''\n",
    "        \n",
    "        if type(X) != np.ndarray:\n",
    "            X = np.array(X)\n",
    "        if type(y) != np.ndarray:\n",
    "            y = np.array(y).reshape(-1,1)\n",
    "            \n",
    "        # give fit the parameter randomstate and whenever it is not None, the weights\n",
    "        # are reset to be random normal - this ensures random starting point of gradient descent\n",
    "        if randomstate is not None:\n",
    "            self.W = np.random.normal(0.0, 0.1, self.N)\n",
    "            self.b = np.random.normal(0.0, 1.0)\n",
    "        \n",
    "        # Save the history of the losses. Why?\n",
    "        history = []\n",
    "        # If we want to calculate the gradient in buckets (look for description of the batch)\n",
    "        bucket_num = len(X) // batch\n",
    "        # slice the data onto batches without shuffling (no stochasticity)\n",
    "        slicing = lambda x, b: x[(b-1)*batch:b*batch]\n",
    "        \n",
    "        # iterate epochs\n",
    "        for epo in range(self.epo):\n",
    "            # iterate batches\n",
    "            loss = 0.0\n",
    "            for bin in range(1, bucket_num + 1):\n",
    "                X_slice = slicing(X,bin)\n",
    "                y_slice = slicing(y,bin)\n",
    "                # predict the output for a given slice (what is the shape of the output?)\n",
    "                pred = self.predict(X_slice)\n",
    "                \n",
    "                suma_b, suma_w = self.gradient(X_slice, y_slice, pred.flatten())\n",
    "\n",
    "                # calculate loss\n",
    "                loss += self.loss(y_slice, pred.flatten())\n",
    "                \n",
    "                # update the weights\n",
    "                self.W += np.mean(suma_w) * self.lr\n",
    "                self.b += np.mean(suma_b) * self.lr\n",
    "            # calculate average loss\n",
    "            loss/=bucket_num\n",
    "\n",
    "            history.append(loss.flatten())\n",
    "        return np.array(history).flatten()\n",
    "    \n",
    "    def plot_history(self, history, ax = None):\n",
    "        '''\n",
    "        Basic history plot\n",
    "        '''        \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        ax.set_xlabel('epo')\n",
    "        ax.set_ylabel('loss')\n",
    "        ax.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6013986013986014\n",
      "Scikit-learn Logistic Regression Accuracy: 0.7552447552447552\n"
     ]
    }
   ],
   "source": [
    "X = df_train_processed.drop('Survived', axis=1)\n",
    "y = df_train_processed['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "perceptron_model = PerceptronLogistic(W=np.zeros(X_train.shape[1]), b=0.0, epo=500, lr=2e-3)\n",
    "history = perceptron_model.fit(X_train_scaled, y_train, randomstate=42, batch=32, verbose=True)\n",
    "y_pred = perceptron_model.predict(X_test_scaled)\n",
    "y_pred_binary = (y_pred >= 0.7).astype(int)\n",
    "accuracy = np.mean(y_pred_binary.flatten() == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Use scikit-learn's Logistic Regression as a benchmark\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_accuracy = lr_model.score(X_test_scaled, y_test)\n",
    "print(f\"Scikit-learn Logistic Regression Accuracy: {lr_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4YxOo4SC0mr"
   },
   "source": [
    "### Suport Vector Machine\n",
    "\n",
    "Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. It is commonly used in classification problems where occur non-linear decision boundaries.  It aims to find the optimal hyperplane that separates different classes in the input space. In project, vectors are in 6-th dimention (described by 6 values: Pclass, Sex, Age, SibSp, Parch and Fare). Support vectors are data points from each class that are closest to the hyperplane. They play a crucial role in determining the optimal hyperplane and maximizing the margin between classes - the distance between the hyperplane and the nearest data point from each class.\n",
    "\n",
    "There was unsuccesfull attempt to implement SVM class from scratch. A Decision was made to implement model using only scikit-learn package functions. Nevertheless, different kernel functions were used: linear, polynomial, radial basis function (RBF) and sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of linear kernel SVM: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "### linear kernel\n",
    "svm_model = SVC(kernel='linear')  #try different kernels\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# making predictions on the test set\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# evaluating accuracies\n",
    "accuracy = svm_model.score(X_test, Y_test)\n",
    "print(f\"Accuracy of linear kernel SVM: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of poly kernel SVM: 0.6388888888888888\n"
     ]
    }
   ],
   "source": [
    "### poly kernel\n",
    "svm_model = SVC(kernel='poly')  #try different kernels\n",
    "svm_model.fit(X_train, Y_train)\n",
    "predictions = svm_model.predict(X_test)\n",
    "accuracy = svm_model.score(X_test, Y_test)\n",
    "print(f\"Accuracy of poly kernel SVM: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Radial Basis Function kernel SVM: 0.6574074074074074\n"
     ]
    }
   ],
   "source": [
    "### Radial Basis Function kernel\n",
    "svm_model = SVC(kernel='rbf')  #try different kernels\n",
    "svm_model.fit(X_train, Y_train)\n",
    "predictions = svm_model.predict(X_test)\n",
    "accuracy = svm_model.score(X_test, Y_test)\n",
    "print(f\"Accuracy of Radial Basis Function kernel SVM: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sigmoid kernel SVM: 0.6203703703703703\n"
     ]
    }
   ],
   "source": [
    "### sigmoid kernel\n",
    "svm_model = SVC(kernel='sigmoid')  #try different kernels\n",
    "svm_model.fit(X_train, Y_train)\n",
    "predictions = svm_model.predict(X_test)\n",
    "accuracy = svm_model.score(X_test, Y_test)\n",
    "print(f\"Accuracy of sigmoid kernel SVM: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best accuracy was reached for linear kernel SVM, and it was used for final prediction for Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass  Sex       Age  SibSp  Parch      Fare\n",
      "0            892       3    0  34.50000      0      0    7.8292\n",
      "1            893       3    1  47.00000      1      0    7.0000\n",
      "2            894       2    0  62.00000      0      0    9.6875\n",
      "3            895       3    0  27.00000      0      0    8.6625\n",
      "4            896       3    1  22.00000      1      1   12.2875\n",
      "..           ...     ...  ...       ...    ...    ...       ...\n",
      "413         1305       3    0  30.27259      0      0    8.0500\n",
      "414         1306       1    1  39.00000      0      0  108.9000\n",
      "415         1307       3    0  38.50000      0      0    7.2500\n",
      "416         1308       3    0  30.27259      0      0    8.0500\n",
      "417         1309       3    0  30.27259      1      1   22.3583\n",
      "\n",
      "[418 rows x 7 columns]\n",
      "\n",
      "NaN rows in test set:\n",
      "Empty DataFrame\n",
      "Columns: [PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked]\n",
      "Index: []\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "# save the results\n",
    "predictions = svm_model.predict(df_test_processed[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].values)\n",
    "output = pd.DataFrame({'PassengerId': df_test_processed.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('SVM_kaggle_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efv0crrNC7Aw"
   },
   "source": [
    "#### Random Forest Model\n",
    "##### To do:\n",
    "- arono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random forest (kaggle example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Classifier: 0.8159371492704826\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "test_data = df_test\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(df_train[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = model.score(X, y)\n",
    "print(f\"Accuracy of Random Forest Classifier: {accuracy}\")\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('RF_kaggle_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaJFk54ICW0c"
   },
   "source": [
    "#### Analysis of results\n",
    "\n",
    "JAK PCA TO MOŻNA BIBLIOTEK UŻYĆ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "To do:\n",
    "- did we reachedour goals?\n",
    "- what is interesting in our solutions\n",
    "- what could be done better? limits and possible improvement"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
