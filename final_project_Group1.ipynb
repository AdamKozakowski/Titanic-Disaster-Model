{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S8EghnyjxYg"
   },
   "source": [
    "# Titanic disaster model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inrotuction\n",
    "#### to do:\n",
    "- briefly describe model\n",
    "- talk about recent methods used for problems like this\\\n",
    "- talk about methods we want to use\n",
    "- what do we expect\n",
    "\n",
    "https://www.kaggle.com/competitions/titanic\n",
    "\n",
    "https://www.kaggle.com/code/alexisbcook/titanic-tutorial/notebook\n",
    "\n",
    "https://www.overleaf.com/read/fqxnygwqtnjs#fbe3c8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxNBdgCNCZSn"
   },
   "source": [
    "### Seting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from scipy import optimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.optimize import minimize, LinearConstraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1700692440573,
     "user": {
      "displayName": "Kirill Korzuk",
      "userId": "04732590717018364342"
     },
     "user_tz": -180
    },
    "id": "C0ZWTfkFj8XM",
    "outputId": "5c778832-e116-4fb5-96f0-eef0058f510c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_path = 'https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/'\n",
    "df_train = pd.read_csv(gh_path + 'train.csv')\n",
    "df_test = pd.read_csv(gh_path + 'test.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59rMrjvLCnLY"
   },
   "source": [
    "### Feature engeneering\n",
    "#### To do:\n",
    "- change values of sex to binary (f.e. male = 0, female = 1),\n",
    "- reduce number of values (drop columns: Name, Ticket, ?Fare?, Cabin, Embarked),\n",
    "- drop keys with NaN values\n",
    "\n",
    "A: Fare value can carry some information about Cabin, if we want to include passenger placement in model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "XvEKGNJ6Crfu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
      "0              1         0       3    0  22.0      1      0   7.2500\n",
      "1              2         1       1    1  38.0      1      0  71.2833\n",
      "2              3         1       3    1  26.0      0      0   7.9250\n",
      "3              4         1       1    1  35.0      1      0  53.1000\n",
      "4              5         0       3    0  35.0      0      0   8.0500\n",
      "..           ...       ...     ...  ...   ...    ...    ...      ...\n",
      "885          886         0       3    1  39.0      0      5  29.1250\n",
      "886          887         0       2    0  27.0      0      0  13.0000\n",
      "887          888         1       1    1  19.0      0      0  30.0000\n",
      "889          890         1       1    0  26.0      0      0  30.0000\n",
      "890          891         0       3    0  32.0      0      0   7.7500\n",
      "\n",
      "[714 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['Name','Ticket', 'Cabin', 'Embarked']\n",
    "df_train_processed = df_train.drop(columns=columns_to_drop)\n",
    "df_test_processed = df_test.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop keys with any NaN values\n",
    "df_train_processed = df_train_processed.dropna()\n",
    "df_test_processed = df_test_processed.dropna()\n",
    "\n",
    "# Sex changed to binary\n",
    "df_train_processed['Sex'] = df_train_processed['Sex'].replace({'male': 0, 'female': 1})\n",
    "df_test_processed['Sex'] = df_test_processed['Sex'].replace({'male': 0, 'female': 1})\n",
    "\n",
    "print(df_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMJqmV_FCw36"
   },
   "source": [
    "### Perceptron\n",
    "\n",
    "#### To do:\n",
    "- define weight vector W (imo randomly) and training set X\n",
    "- DONE definition of perceptron class (linear, binary[if survived would be changed to -1 and 1] or/and LOGISTIC). That would include: activation function, loss function, fiting (gradient descent/newton-rap), all can be copied and slightly modified form collab \"logistic_regression_and_svm\",\n",
    "- spliting training dataset and look for bad predictions,\n",
    "- comparason with scikit-learn method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1700566854641,
     "user": {
      "displayName": "Adam Kozakowski",
      "userId": "03759211285170292721"
     },
     "user_tz": -60
    },
    "id": "ND2iJXTwCwnD",
    "outputId": "4b465522-e449-4195-effd-2eb87646d420"
   },
   "outputs": [],
   "source": [
    "class PerceptronLogistic:\n",
    "    def __init__(self, W : np.array,  b = 0, epo = 100, lr = 0.01):\n",
    "        self.W = W\n",
    "        self.N = len(W)\n",
    "        self.b = b\n",
    "        # how many learning iterations we give\n",
    "        self.epo = epo\n",
    "        # what is our step in the gradient\n",
    "        self.lr = lr\n",
    "    def get_N(self):\n",
    "        return self.N\n",
    "    \n",
    "    def get_b(self):\n",
    "        return self.b\n",
    "    \n",
    "    def get_W(self):\n",
    "        return self.W\n",
    "    \n",
    "    ############################## SETTERS ##############################\n",
    "    \n",
    "    # Create setters for the perceptron\n",
    "    def set_N(self, N):\n",
    "        self.N = N\n",
    "        self.W = np.zeros(N)\n",
    "        \n",
    "    def set_b(self, b):\n",
    "        self.b = b\n",
    "        \n",
    "    def set_W(self, W : np.array):\n",
    "        if W.ndim != 1:\n",
    "            print(\"Cannot set such weights -> dimension wrong\")\n",
    "            return\n",
    "        self.N = W.shape[0]\n",
    "        self.W = W\n",
    "    \n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def set_epo(self, epo):\n",
    "        self.epo = epo\n",
    "    ############################## GETTERS OVERRIDE ##############################\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.W[key]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.W[key] = value\n",
    "        \n",
    "    def __getslice(self, i, j):\n",
    "        return self.W[i:j]\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.lr\n",
    "\n",
    "    def get_epo(self):\n",
    "        return self.epo\n",
    "    \n",
    "    # set the string output of the perceptron \n",
    "    def __str__(self):\n",
    "        return f\"Am a perceptron of N={self.N} dimension{'s' if self.N > 1 else ''} biased with b={self.b}\"    \n",
    "\n",
    "    ############################## OPERATORS OVERRIDE ##############################\n",
    "     \n",
    "    def __mul__(self, other):\n",
    "        return self.activation_function(other)\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        return self.__mul__(other)\n",
    "\n",
    "    ############################## PERCEPTRON METHODS ##############################\n",
    "    \n",
    "    '''\n",
    "    Net output is the basic body action of the perceptron. On top of it, the activation function is used.\n",
    "    '''\n",
    "    def net_output(self, X):\n",
    "        return np.dot(X, self.W) + self.b\n",
    "\n",
    "    def activation_function(self, X):\n",
    "        net_output = self.net_output(X)\n",
    "        return (1.0 / (1.0 + np.exp(-np.clip(net_output, -500, 500)))).reshape(-1, 1)\n",
    "\n",
    "    def loss(self, y_true : np.array, y_pred : np.array, lambd=0.1):\n",
    "            epsilon = 1e-15\n",
    "            y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "            regularizer = (lambd / 2) * np.sum(self.W**2)\n",
    "            return -np.sum(np.multiply(y_true, np.log(y_pred)) + np.multiply((1.0 - y_true), np.log(1.0 - y_pred))) + regularizer\n",
    "\n",
    "    def gradient(self, x_true, y_true, prediction):\n",
    "        val = y_true - prediction\n",
    "        suma_w = np.dot(val, x_true)\n",
    "        suma_b = np.sum(val)\n",
    "        return suma_b, suma_w\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.activation_function(X)    \n",
    "\n",
    "    def fit(self, X, y, randomstate = None, batch = 1, verbose = False):\n",
    "        '''\n",
    "        Fit function allows to obtain the (probably most?) correct weights for the perceptron via the gradient descent algorithm.\n",
    "        '''\n",
    "        \n",
    "        if type(X) != np.ndarray:\n",
    "            X = np.array(X)\n",
    "        if type(y) != np.ndarray:\n",
    "            y = np.array(y).reshape(-1,1)\n",
    "            \n",
    "        # give fit the parameter randomstate and whenever it is not None, the weights\n",
    "        # are reset to be random normal - this ensures random starting point of gradient descent\n",
    "        if randomstate is not None:\n",
    "            self.W = np.random.normal(0.0, 0.1, self.N)\n",
    "            self.b = np.random.normal(0.0, 1.0)\n",
    "        \n",
    "        # Save the history of the losses. Why?\n",
    "        history = []\n",
    "        # If we want to calculate the gradient in buckets (look for description of the batch)\n",
    "        bucket_num = len(X) // batch\n",
    "        # slice the data onto batches without shuffling (no stochasticity)\n",
    "        slicing = lambda x, b: x[(b-1)*batch:b*batch]\n",
    "        \n",
    "        # iterate epochs\n",
    "        for epo in range(self.epo):\n",
    "            # iterate batches\n",
    "            loss = 0.0\n",
    "            for bin in range(1, bucket_num + 1):\n",
    "                X_slice = slicing(X,bin)\n",
    "                y_slice = slicing(y,bin)\n",
    "                # predict the output for a given slice (what is the shape of the output?)\n",
    "                pred = self.predict(X_slice)\n",
    "                \n",
    "                suma_b, suma_w = self.gradient(X_slice, y_slice, pred.flatten())\n",
    "\n",
    "                # calculate loss\n",
    "                loss += self.loss(y_slice, pred.flatten())\n",
    "                \n",
    "                # update the weights\n",
    "                self.W += np.mean(suma_w) * self.lr\n",
    "                self.b += np.mean(suma_b) * self.lr\n",
    "            # calculate average loss\n",
    "            loss/=bucket_num\n",
    "            # if verbose:\n",
    "                # print(f'epo:{epo}->loss={loss}')\n",
    "            history.append(loss.flatten())\n",
    "        return np.array(history).flatten()\n",
    "\n",
    "\n",
    "    def plot_history(self, history, ax = None):\n",
    "        '''\n",
    "        Basic history plot\n",
    "        '''        \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "        ax.set_xlabel('epo')\n",
    "        ax.set_ylabel('loss')\n",
    "        ax.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skylearn attempt\n",
    "X = df_train_processed.drop('Survived', axis=1)\n",
    "y = df_train_processed['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3916083916083916\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "perceptron_model = PerceptronLogistic(W=np.zeros(X_train.shape[1]), b=0.1, epo=1000, lr=2e-3)\n",
    "history = perceptron_model.fit(X_train, y_train, randomstate=42, batch=32, verbose=True)\n",
    "y_pred = perceptron_model.predict(X_test)\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "accuracy = np.mean(y_pred_binary.flatten() == y_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Logistic Regression Accuracy: 0.7552447552447552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Use scikit-learn's Logistic Regression as a benchmark\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_accuracy = lr_model.score(X_test_scaled, y_test)\n",
    "print(f\"Scikit-learn Logistic Regression Accuracy: {lr_accuracy}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4YxOo4SC0mr"
   },
   "source": [
    "### Suport Vector Machine\n",
    "#### To do: \n",
    "- define 6D weight vector (Pclass,Sex,Age,SibSp,Parch,Fare), loss function (Lagrange function), calculate width of the margin (constraint equation), Optimize and get the values of $\\vec{\\alpha}$, w and bias b.  kernel transformation(s),\n",
    "- soft- (leanring rate (regulatization) C) and hard-margin,\n",
    "- spliting training dataset and look for bad predictions,\n",
    "- compare with scikit-learn method.\n",
    "\n",
    "$$ L(\\vec{\\alpha}) = \\sum _i \\alpha _i - \\frac{1}{2} \\sum _{i,j} \\alpha _i \\alpha _j y_i y_j \\vec{X}_i\\cdot \\vec{X} _j. $$\n",
    "Kuhn-Tucker theorem: the solution we find here will be the same as the solution to the original problem\n",
    "##### [`REMARK`] It's crucial to keep track of this equation and the dot product within it, as it becomes highly significant later on, especially when dealing with nonlinear data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_train_processed['Survived'].values\n",
    "X = df_train_processed[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mAccuracy: \u001B[39m\u001B[39m{\u001B[39;00maccuracy\u001B[39m}\u001B[39;00m\u001B[39m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[39m# save the results\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m output \u001B[39m=\u001B[39m pd\u001B[39m.\u001B[39mDataFrame({\u001B[39m'\u001B[39m\u001B[39mPassengerId\u001B[39m\u001B[39m'\u001B[39m: test_data\u001B[39m.\u001B[39mPassengerId, \u001B[39m'\u001B[39m\u001B[39mSurvived\u001B[39m\u001B[39m'\u001B[39m: predictions})\n\u001B[0;32m     14\u001B[0m output\u001B[39m.\u001B[39mto_csv(\u001B[39m'\u001B[39m\u001B[39mRF_kaggle_submission.csv\u001B[39m\u001B[39m'\u001B[39m, index\u001B[39m=\u001B[39m\u001B[39mFalse\u001B[39;00m)\n\u001B[0;32m     15\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39m\"\u001B[39m\u001B[39mYour submission was successfully saved!\u001B[39m\u001B[39m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "#sklearn for comparason\n",
    "svm_model = SVC(kernel='linear')  #try different kernels\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = svm_model.score(X_test, Y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# # save the results\n",
    "# output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "# output.to_csv('SVM_kaggle_submission.csv', index=False)\n",
    "# print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efv0crrNC7Aw"
   },
   "source": [
    "#### Random Forest Model\n",
    "##### To do:\n",
    "- arono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random forest (kaggle example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[39mfrom\u001B[39;00m \u001B[39msklearn\u001B[39;00m\u001B[39m.\u001B[39;00m\u001B[39mensemble\u001B[39;00m \u001B[39mimport\u001B[39;00m RandomForestClassifier\n\u001B[1;32m----> 2\u001B[0m test_data \u001B[39m=\u001B[39m df_test\n\u001B[0;32m      3\u001B[0m y \u001B[39m=\u001B[39m df_train[\u001B[39m\"\u001B[39m\u001B[39mSurvived\u001B[39m\u001B[39m\"\u001B[39m]\n\u001B[0;32m      5\u001B[0m features \u001B[39m=\u001B[39m [\u001B[39m\"\u001B[39m\u001B[39mPclass\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39mSex\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39mSibSp\u001B[39m\u001B[39m\"\u001B[39m, \u001B[39m\"\u001B[39m\u001B[39mParch\u001B[39m\u001B[39m\"\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "test_data = df_test\n",
    "y = df_train[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "X = pd.get_dummies(df_train[features])\n",
    "X_test = pd.get_dummies(test_data[features])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('RF_kaggle_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UaJFk54ICW0c"
   },
   "source": [
    "#### Analysis of results\n",
    "\n",
    "JAK PCA TO MOÅ»NA BIBLIOTEK UÅ»YÄ† \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "To do:\n",
    "- did we reachedour goals?\n",
    "- what is interesting in our solutions\n",
    "- what could be done better? limits and possible improvement"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
